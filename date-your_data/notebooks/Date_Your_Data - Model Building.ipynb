{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', low_memory=False, parse_dates=['Earliest_Start_Date'])\n",
    "students = pd.read_csv('../data/Student.csv')\n",
    "internship = pd.read_csv('../data/Internship.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_hot_encoded_skill_features = internship.columns[13:]\n",
    "internship = internship[internship.columns.drop(one_hot_encoded_skill_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with internship details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_with_internship = pd.merge(train, internship, how='left', on='Internship_ID')\n",
    "test_with_internship = pd.merge(test, internship, how='left', on='Internship_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with student details as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    df['num_experience'] = df.shape[0]\n",
    "    df['num_exp_in_job'] = (df.Experience_Type  == 'job').sum()\n",
    "    df['num_awards'] = (df.Experience_Type  == 'award').sum()\n",
    "    df['num_previous_internships'] = (df.Experience_Type == 'internship').sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "students_cleaned = students.groupby('Student_ID').apply(feature_engineer)\n",
    "students_cleaned = students_cleaned.groupby('Student_ID').first()\n",
    "students_cleaned = students_cleaned.reset_index()\n",
    "\n",
    "train_merged = pd.merge(train_with_internship, students_cleaned, on='Student_ID', how='left')\n",
    "test_merged = pd.merge(test_with_internship, students_cleaned, on='Student_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save these engineered files so that we don't have to create them every time\n",
    "train_merged.to_csv('../data/train_merged.csv', index=False)\n",
    "test_merged.to_csv('../data/test_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_columns = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date', 'Internship_deadline']\n",
    "\n",
    "train_merged = pd.read_csv('../data/train_merged.csv', parse_dates=date_columns)\n",
    "test_merged = pd.read_csv('../data/test_merged.csv', parse_dates=date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Skills_required'] = train_merged.Skills_required.fillna('-1')\n",
    "test_merged.loc[:, 'Skills_required'] = test_merged.Skills_required.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.Stipend1 = train_merged.Stipend1.fillna(train_merged.Stipend1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'is_stipend_performance_or_unpaid'] = train_merged.Stipend_Type.map(lambda x: int(x in [1, 2]))\n",
    "test_merged.loc[:, 'is_stipend_performance_or_unpaid'] = test_merged.Stipend_Type.map(lambda x: int(x in [1, 2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))\n",
    "test_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salary_mapping(salary):\n",
    "    if salary < 2000:\n",
    "        return 'No Expectations'\n",
    "    elif salary >= 2000 and salary < 5000:\n",
    "        return '2-5K'\n",
    "    elif salary >= 5000 and salary < 10000:\n",
    "        return '5-10K'\n",
    "    else:\n",
    "        return '10K+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Stipend_level'] = train_merged.Stipend1.map(salary_mapping)\n",
    "test_merged.loc[:, 'Stipend_level'] = test_merged.Stipend1.map(salary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_stipend_train = train_merged.Stipend1.mean()\n",
    "avg_stipend_test = test_merged.Stipend1.mean()\n",
    "\n",
    "get_stipend_train = lambda x: int((x['Stipend_Type'] in ['fixed', 'performance']) and x['Stipend1'] < avg_stipend_train)\n",
    "get_stipend_test = lambda x: int((x['Stipend_Type'] in ['fixed', 'performance']) and x['Stipend1'] < avg_stipend_test)\n",
    "\n",
    "train_merged.loc[:, 'less_than_avg_salary'] = train_merged.apply(get_stipend_train, axis=1)\n",
    "test_merged.loc[:, 'less_than_avg_salary'] = test_merged.apply(get_stipend_test, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2017, 2012, 2014, 2016, 2013, 2011, 2019, 2018, 2009, 2010,\n",
       "       2001, 2020], dtype=int64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.Year_of_graduation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2015, 2014, 2018, 2013, 2012, 2017, 2011, 2010, 2009, 2019,\n",
       "       2001, 2020], dtype=int64)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged.Year_of_graduation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_stipend(df):\n",
    "    year_of_grad = df['Year_of_graduation'].unique()\n",
    "    mapping = {}\n",
    "    \n",
    "    for year in year_of_grad:\n",
    "        mapping[year] = df[df['Year_of_graduation'] == year].Stipend1.mean()\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "train_map = get_mean_stipend(train_merged)\n",
    "test_map = get_mean_stipend(test_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_expectation_level_train(row):\n",
    "    year_of_grad = row['Year_of_graduation']\n",
    "    mean_stipend = train_map[year_of_grad]\n",
    "    stipend1 = row['Stipend1']\n",
    "    \n",
    "    return int ( stipend1 < mean_stipend ) \n",
    "\n",
    "def calculate_expectation_level_test(row):\n",
    "    year_of_grad = row['Year_of_graduation']\n",
    "    mean_stipend = test_map[year_of_grad]\n",
    "    stipend1 = row['Stipend1']\n",
    "    \n",
    "    return int ( stipend1 < mean_stipend ) \n",
    "\n",
    "\n",
    "train_merged.loc[:, 'stipend_expectation_by_exp'] = train_merged.apply(calculate_expectation_level_train, axis=1)\n",
    "test_merged.loc[:, 'stipend_expectation_by_exp'] = test_merged.apply(calculate_expectation_level_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_if_expectations_match(row):\n",
    "    expected_stipend = row['Expected_Stipend']\n",
    "    stipend_level = row['Stipend_level']\n",
    "    \n",
    "    if expected_stipend == 'No Expectations':\n",
    "        return 1\n",
    "    elif expected_stipend == '2-5K':\n",
    "        if stipend_level in ['2-5K', '5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '5-10K':\n",
    "        if stipend_level in ['5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '10K+':\n",
    "        if stipend_level == '10K+':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "train_merged.loc[:, 'expectations_match'] = train_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)\n",
    "test_merged.loc[:, 'expectations_match'] = test_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Earliest_Start_Date_month'] = train_merged.Earliest_Start_Date.dt.month\n",
    "test_merged.loc[:, 'Earliest_Start_Date_month'] = test_merged.Earliest_Start_Date.dt.month\n",
    "\n",
    "train_merged.loc[:, 'is_Dec_or_Jan'] = train_merged.Earliest_Start_Date_month.map(lambda x: int(x == 12 or x == 1))\n",
    "test_merged.loc[:, 'is_Dec_or_Jan'] = test_merged.Earliest_Start_Date_month.map(lambda x: int(x == 12 or x == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_features = train_merged.select_dtypes(include=['object']).columns.drop(['Skills_required', 'Profile', 'Degree'])\n",
    "\n",
    "for feature in categorical_features:\n",
    "    lbl = LabelEncoder()\n",
    "    feature_range = pd.concat([train_merged[feature], test_merged[feature]], axis=0)\n",
    "    \n",
    "    lbl.fit(feature_range)\n",
    "    train_merged.loc[:, feature] = lbl.transform(train_merged[feature])\n",
    "    test_merged.loc[:, feature] = lbl.transform(test_merged[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged = train_merged.fillna(999)\n",
    "test_merged = test_merged.fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_merged = train_merged.replace(-999, 999)\n",
    "# test_merged = test_merged.replace(-999, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    170208\n",
       "0     22374\n",
       "Name: is_Dec_or_Jan, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.is_Dec_or_Jan.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                    'Is_Shortlisted', 'Internship_deadline', 'Internship_Profile',\n",
    "                    'Profile', 'Stipend2', 'PG_scale', 'UG_Scale', 'Skills_required',\n",
    "                    'Degree']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "features = train_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_merged[features]\n",
    "y = train_merged.Is_Shortlisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_sample = np.random.randint(0, X.shape[0], size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[random_sample]\n",
    "y_train = y.iloc[random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_index = X[~X.Internship_ID.isin(X_train.Internship_ID)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X.ix[test_index]\n",
    "y_test = y.ix[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 37) (10656, 37) (15000L,) (10656L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=25)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# clf = LogisticRegression(C=1., penalty='l1', class_weight='auto')\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=3, min_samples_split=3, n_jobs=-1)\n",
    "# clf = ExtraTreesClassifier(n_estimators=350, min_samples_split=5, class_weight='auto', max_depth=3, n_jobs=-1)\n",
    "# clf = GradientBoostingClassifier()\n",
    "# clf = XGBClassifier()\n",
    "\n",
    "# pipeline = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "pipeline = Pipeline([('clf', clf)])\n",
    "\n",
    "# pipeline = Pipeline([('select', select), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=750, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'mean score %.2f and std %.2f ' %(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.Skills_required.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.164546\n",
      " 2) Student_ID                     0.141308\n",
      " 3) Expected_Stipend               0.139328\n",
      " 4) Minimum_Duration               0.055127\n",
      " 5) Preferred_location             0.048159\n",
      " 6) Is_Part_Time                   0.045961\n",
      " 7) Internship_Type                0.043041\n",
      " 8) Internship_Location            0.042725\n",
      " 9) Internship_category            0.035343\n",
      "10) No_of_openings                 0.033308\n",
      "11) Stipend_Type                   0.031789\n",
      "12) Stipend1                       0.027245\n",
      "13) Internship_Duration(Months)    0.021694\n",
      "14) Institute_Category             0.020378\n",
      "15) Institute_location             0.017301\n",
      "16) hometown                       0.014464\n",
      "17) Stream                         0.013980\n",
      "18) Current_year                   0.013622\n",
      "19) Year_of_graduation             0.013281\n",
      "20) Performance_PG                 0.011027\n",
      "21) Performance_UG                 0.009370\n",
      "22) Performance_12th               0.008996\n",
      "23) Performance_10th               0.006120\n",
      "24) Experience_Type                0.005972\n",
      "25) Location                       0.005414\n",
      "26) num_experience                 0.004942\n",
      "27) num_exp_in_job                 0.004826\n",
      "28) num_awards                     0.004234\n",
      "29) num_previous_internships       0.003275\n",
      "30) is_stipend_performance_or_unpaid 0.003256\n",
      "31) Num_Skills_Required            0.002405\n",
      "32) Stipend_level                  0.002343\n",
      "33) less_than_avg_salary           0.001976\n",
      "34) expectations_match             0.001638\n",
      "35) Earliest_Start_Date_month      0.001607\n",
      "36) is_Dec_or_Jan                  0.000000\n",
      "37) stipend_expectation_by_exp     0.000000\n"
     ]
    }
   ],
   "source": [
    "# RF feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.112838\n",
      " 2) Student_ID                     0.110488\n",
      " 3) Expected_Stipend               0.081714\n",
      " 4) Minimum_Duration               0.073927\n",
      " 5) Preferred_location             0.049659\n",
      " 6) Is_Part_Time                   0.047065\n",
      " 7) Internship_Type                0.040350\n",
      " 8) Internship_Location            0.039712\n",
      " 9) Internship_category            0.039164\n",
      "10) No_of_openings                 0.038776\n",
      "11) Stipend_Type                   0.037496\n",
      "12) Stipend1                       0.029431\n",
      "13) Internship_Duration(Months)    0.027383\n",
      "14) Institute_Category             0.023922\n",
      "15) Institute_location             0.021115\n",
      "16) hometown                       0.020669\n",
      "17) Stream                         0.019968\n",
      "18) Current_year                   0.019587\n",
      "19) Year_of_graduation             0.019051\n",
      "20) Performance_PG                 0.018515\n",
      "21) Performance_UG                 0.017904\n",
      "22) Performance_12th               0.015356\n",
      "23) Performance_10th               0.013894\n",
      "24) Experience_Type                0.013624\n",
      "25) Location                       0.013146\n",
      "26) num_experience                 0.012727\n",
      "27) num_exp_in_job                 0.008740\n",
      "28) num_awards                     0.007190\n",
      "29) num_previous_internships       0.006369\n",
      "30) is_stipend_performance_or_unpaid 0.005064\n",
      "31) Num_Skills_Required            0.004476\n",
      "32) Stipend_level                  0.004263\n",
      "33) less_than_avg_salary           0.004085\n",
      "34) expectations_match             0.002333\n",
      "35) Earliest_Start_Date_month      0.000000\n",
      "36) is_Dec_or_Jan                  0.000000\n"
     ]
    }
   ],
   "source": [
    "# GBM feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsTrain = (pipeline.predict_proba(X_train)[:, 1])\n",
    "predsTest = (pipeline.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on training set 0.670004 \n",
      "AUC score on test set 0.621218 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score on training set %f ' %(roc_auc_score(y_train, predsTrain))\n",
    "print 'AUC score on test set %f ' %(roc_auc_score(y_test, predsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                    'Internship_deadline', 'Internship_Profile',\n",
    "                    'Profile', 'Stipend2', 'PG_scale', 'UG_Scale', 'Skills_required',\n",
    "                    'Degree']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "features = test_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test_merged[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = (pipeline.predict_proba(test_features)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/submission.csv')\n",
    "submission['Internship_ID'] = test_merged.Internship_ID\n",
    "submission['Student_ID'] = test_merged.Student_ID\n",
    "submission['Is_Shortlisted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/redate_salary_expectation_increased_estimators.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
