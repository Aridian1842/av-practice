{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', low_memory=False, parse_dates=['Earliest_Start_Date'])\n",
    "students = pd.read_csv('../data/Student.csv')\n",
    "internship = pd.read_csv('../data/Internship.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_hot_encoded_skill_features = internship.columns[13:]\n",
    "internship = internship[internship.columns.drop(one_hot_encoded_skill_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with internship details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_with_internship = pd.merge(train, internship, how='left', on='Internship_ID')\n",
    "test_with_internship = pd.merge(test, internship, how='left', on='Internship_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with student details as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    df['num_experience'] = df.shape[0]\n",
    "    df['num_exp_in_job'] = (df.Experience_Type  == 'job').sum()\n",
    "    df['num_awards'] = (df.Experience_Type  == 'award').sum()\n",
    "    df['num_previous_internships'] = (df.Experience_Type == 'internship').sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "students_cleaned = students.groupby('Student_ID').apply(feature_engineer)\n",
    "students_cleaned = students_cleaned.groupby('Student_ID').first()\n",
    "students_cleaned = students_cleaned.reset_index()\n",
    "\n",
    "train_merged = pd.merge(train_with_internship, students_cleaned, on='Student_ID', how='left')\n",
    "test_merged = pd.merge(test_with_internship, students_cleaned, on='Student_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save these engineered files so that we don't have to create them every time\n",
    "train_merged.to_csv('../data/train_merged.csv', index=False)\n",
    "test_merged.to_csv('../data/test_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# date_columns = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date', 'Internship_deadline']\n",
    "\n",
    "train_merged = pd.read_csv('../data/train_merged.csv')\n",
    "test_merged = pd.read_csv('../data/test_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Skills_required'] = train_merged.Skills_required.fillna('-1')\n",
    "test_merged.loc[:, 'Skills_required'] = test_merged.Skills_required.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.Stipend1 = train_merged.Stipend1.fillna(train_merged.Stipend1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))\n",
    "test_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salary_mapping(salary):\n",
    "    if salary < 2000:\n",
    "        return 'No Expectations'\n",
    "    elif salary >= 2000 and salary < 5000:\n",
    "        return '2-5K'\n",
    "    elif salary >= 5000 and salary < 10000:\n",
    "        return '5-10K'\n",
    "    else:\n",
    "        return '10K+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Stipend_level'] = train_merged.Stipend1.map(salary_mapping)\n",
    "test_merged.loc[:, 'Stipend_level'] = test_merged.Stipend1.map(salary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_stipend_train = train_merged.Stipend1.mean()\n",
    "avg_stipend_test = test_merged.Stipend1.mean()\n",
    "\n",
    "train_merged.loc[:, 'less_than_avg_salary'] = train_merged.Stipend1.map(lambda x: int(x < avg_stipend_train))\n",
    "test_merged.loc[:, 'less_than_avg_salary'] = test_merged.Stipend1.map(lambda x: int(x < avg_stipend_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_if_expectations_match(row):\n",
    "    expected_stipend = row['Expected_Stipend']\n",
    "    stipend_level = row['Stipend_level']\n",
    "    \n",
    "    if expected_stipend == 'No Expectations':\n",
    "        return 1\n",
    "    elif expected_stipend == '2-5K':\n",
    "        if stipend_level in ['2-5K', '5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '5-10K':\n",
    "        if stipend_level in ['5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif stipend_level == '10K+':\n",
    "        if stipend_level == '10K+':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "train_merged.loc[:, 'expectations_match'] = train_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)\n",
    "test_merged.loc[:, 'expectations_match'] = test_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:259: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    }
   ],
   "source": [
    "categorical_features = train_merged.select_dtypes(include=['object']).columns.drop(['Earliest_Start_Date', 'Start_Date',\n",
    "                                                                                    'Start Date', 'End Date', 'Internship_deadline'])\n",
    "\n",
    "for feature in categorical_features:\n",
    "    lbl = LabelEncoder()\n",
    "    feature_range = pd.concat([train_merged[feature], test_merged[feature]], axis=0)\n",
    "    \n",
    "    lbl.fit(feature_range)\n",
    "    train_merged.loc[:, feature] = lbl.transform(train_merged[feature])\n",
    "    test_merged.loc[:, feature] = lbl.transform(test_merged[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged = train_merged.fillna(999)\n",
    "test_merged = test_merged.fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_merged = train_merged.replace(-999, 999)\n",
    "# test_merged = test_merged.replace(-999, 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = train_merged.columns.drop(['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                                      'Is_Shortlisted', 'Internship_deadline', 'Internship_Profile',\n",
    "                                      'Profile', 'Stipend2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_merged[features]\n",
    "y = train_merged.Is_Shortlisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_sample = np.random.randint(0, X.shape[0], size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[random_sample]\n",
    "y_train = y.iloc[random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_index = X[~X.Internship_ID.isin(X_train.Internship_ID)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X.ix[test_index]\n",
    "y_test = y.ix[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 310) (10962, 310) (15000L,) (10962L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=25)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# clf = LogisticRegression(C=1., penalty='l1', class_weight='auto')\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=4, min_samples_split=3, n_jobs=-1)\n",
    "# clf = GradientBoostingClassifier()\n",
    "# clf = XGBClassifier(n_estimators=300, learning_rate=0.008, gamma=5, min_child_weight=5, subsample=0.6, colsample_bytree=0.7)\n",
    "\n",
    "# pipeline = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "# pipeline = Pipeline([('clf', clf)])\n",
    "pipeline = Pipeline([('select', select), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('select', SelectKBest(k=25, score_func=<function chi2 at 0x0000000015B246D8>)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'mean score %.2f and std %.2f ' %(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.Skills_required.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.092016\n",
      " 2) Student_ID                     0.089282\n",
      " 3) Expected_Stipend               0.066643\n",
      " 4) Minimum_Duration               0.053414\n",
      " 5) Preferred_location             0.034551\n",
      " 6) Is_Part_Time                   0.034303\n",
      " 7) Skills_required                0.034126\n",
      " 8) Internship_Type                0.033592\n",
      " 9) Internship_Location            0.033471\n",
      "10) Internship_category            0.032111\n",
      "11) No_of_openings                 0.030226\n",
      "12) Stipend_Type                   0.028327\n",
      "13) Stipend1                       0.027475\n",
      "14) Internship_Duration(Months)    0.026960\n",
      "15) PR                             0.023193\n",
      "16) UI                             0.023133\n",
      "17) Marketing                      0.022791\n",
      "18) Media                          0.021317\n",
      "19) Social                         0.021157\n",
      "20) Design                         0.021086\n",
      "21) Web                            0.019215\n",
      "22) Development                    0.019011\n",
      "23) Business                       0.017779\n",
      "24) Research                       0.017734\n",
      "25) Writing                        0.015262\n",
      "26) Plan                           0.015248\n",
      "27) Creative                       0.014673\n",
      "28) Process                        0.013859\n",
      "29) Database                       0.012064\n",
      "30) Strategy                       0.011261\n",
      "31) Designing                      0.010899\n",
      "32) Analysis                       0.010666\n",
      "33) Facebook                       0.010063\n",
      "34) Communication                  0.009011\n",
      "35) Rest                           0.007769\n",
      "36) Android                        0.007740\n",
      "37) Presentation                   0.006562\n",
      "38) Media Marketing                0.006268\n",
      "39) Twitter                        0.005122\n",
      "40) Social Media Marketing         0.004611\n",
      "41) Operations                     0.004581\n",
      "42) Java                           0.004480\n",
      "43) Quality                        0.003410\n",
      "44) HTML                           0.001773\n",
      "45) Blogs                          0.001470\n",
      "46) Digital Marketing              0.000292\n",
      "47) PHP                            0.000000\n",
      "48) Market Research                0.000000\n",
      "49) Recruitment                    0.000000\n",
      "50) Testing                        0.000000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6b5e7522ea53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%2d) %-*s %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "# RF feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GBM feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsTrain = pipeline.predict_proba(X_train)[:, 1]\n",
    "predsTest = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on training set 0.691441 \n",
      "AUC score on test set 0.582487 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score on training set %f ' %(roc_auc_score(y_train, predsTrain))\n",
    "print 'AUC score on test set %f ' %(roc_auc_score(y_test, predsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('select', SelectKBest(k=25, score_func=<function chi2 at 0x0000000015B246D8>)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features_columns = test_merged.columns.drop(['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                                                  'Internship_deadline', 'Internship_Profile',\n",
    "                                                  'Profile', 'Stipend2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test_merged[test_features_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/submission.csv')\n",
    "submission['Internship_ID'] = test_merged.Internship_ID\n",
    "submission['Student_ID'] = test_merged.Student_ID\n",
    "submission['Is_Shortlisted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/redate_submission_first.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
