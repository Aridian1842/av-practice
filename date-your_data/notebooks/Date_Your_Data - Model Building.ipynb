{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', low_memory=False, parse_dates=['Earliest_Start_Date'])\n",
    "students = pd.read_csv('../data/Student.csv')\n",
    "internship = pd.read_csv('../data/Internship.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_hot_encoded_skill_features = internship.columns[13:]\n",
    "internship = internship[internship.columns.drop(one_hot_encoded_skill_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with internship details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_with_internship = pd.merge(train, internship, how='left', on='Internship_ID')\n",
    "test_with_internship = pd.merge(test, internship, how='left', on='Internship_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with student details as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    df['num_experience'] = df.shape[0]\n",
    "    df['num_exp_in_job'] = (df.Experience_Type  == 'job').sum()\n",
    "    df['num_awards'] = (df.Experience_Type  == 'award').sum()\n",
    "    df['num_previous_internships'] = (df.Experience_Type == 'internship').sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "students_cleaned = students.groupby('Student_ID').apply(feature_engineer)\n",
    "students_cleaned = students_cleaned.groupby('Student_ID').first()\n",
    "students_cleaned = students_cleaned.reset_index()\n",
    "\n",
    "train_merged = pd.merge(train_with_internship, students_cleaned, on='Student_ID', how='left')\n",
    "test_merged = pd.merge(test_with_internship, students_cleaned, on='Student_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save these engineered files so that we don't have to create them every time\n",
    "train_merged.to_csv('../data/train_merged.csv', index=False)\n",
    "test_merged.to_csv('../data/test_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# date_columns = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date', 'Internship_deadline']\n",
    "\n",
    "train_merged = pd.read_csv('../data/train_merged.csv')\n",
    "test_merged = pd.read_csv('../data/test_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Skills_required'] = train_merged.Skills_required.fillna('-1')\n",
    "test_merged.loc[:, 'Skills_required'] = test_merged.Skills_required.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.Stipend1 = train_merged.Stipend1.fillna(train_merged.Stipend1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'is_stipend_performance_or_unpaid'] = train_merged.Stipend_Type.map(lambda x: int(x in [1, 2]))\n",
    "test_merged.loc[:, 'is_stipend_performance_or_unpaid'] = test_merged.Stipend_Type.map(lambda x: int(x in [1, 2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))\n",
    "test_merged.loc[:, 'Num_Skills_Required'] = train_merged.Skills_required.map(lambda x: len(set(x.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salary_mapping(salary):\n",
    "    if salary < 2000:\n",
    "        return 'No Expectations'\n",
    "    elif salary >= 2000 and salary < 5000:\n",
    "        return '2-5K'\n",
    "    elif salary >= 5000 and salary < 10000:\n",
    "        return '5-10K'\n",
    "    else:\n",
    "        return '10K+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Stipend_level'] = train_merged.Stipend1.map(salary_mapping)\n",
    "test_merged.loc[:, 'Stipend_level'] = test_merged.Stipend1.map(salary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_stipend_train = train_merged.Stipend1.mean()\n",
    "avg_stipend_test = test_merged.Stipend1.mean()\n",
    "\n",
    "get_stipend_train = lambda x: int((x['Stipend_Type'] in ['fixed', 'performance']) and x['Stipend1'] < avg_stipend_train)\n",
    "get_stipend_test = lambda x: int((x['Stipend_Type'] in ['fixed', 'performance']) and x['Stipend1'] < avg_stipend_test)\n",
    "\n",
    "train_merged.loc[:, 'less_than_avg_salary'] = train_merged.apply(get_stipend_train, axis=1)\n",
    "test_merged.loc[:, 'less_than_avg_salary'] = test_merged.apply(get_stipend_test, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_if_expectations_match(row):\n",
    "    expected_stipend = row['Expected_Stipend']\n",
    "    stipend_level = row['Stipend_level']\n",
    "    \n",
    "    if expected_stipend == 'No Expectations':\n",
    "        return 1\n",
    "    elif expected_stipend == '2-5K':\n",
    "        if stipend_level in ['2-5K', '5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '5-10K':\n",
    "        if stipend_level in ['5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '10K+':\n",
    "        if stipend_level == '10K+':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "train_merged.loc[:, 'expectations_match'] = train_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)\n",
    "test_merged.loc[:, 'expectations_match'] = test_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "C:\\Users\\Abhishek\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:259: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    }
   ],
   "source": [
    "categorical_features = train_merged.select_dtypes(include=['object']).columns.drop(['Earliest_Start_Date', 'Start_Date',\n",
    "                                                                                    'Start Date', 'End Date', 'Internship_deadline'])\n",
    "\n",
    "for feature in categorical_features:\n",
    "    lbl = LabelEncoder()\n",
    "    feature_range = pd.concat([train_merged[feature], test_merged[feature]], axis=0)\n",
    "    \n",
    "    lbl.fit(feature_range)\n",
    "    train_merged.loc[:, feature] = lbl.transform(train_merged[feature])\n",
    "    test_merged.loc[:, feature] = lbl.transform(test_merged[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged = train_merged.fillna(999)\n",
    "test_merged = test_merged.fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_merged = train_merged.replace(-999, 999)\n",
    "# test_merged = test_merged.replace(-999, 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                                      'Is_Shortlisted', 'Internship_deadline', 'Internship_Profile',\n",
    "                                      'Profile', 'Stipend2', 'PG_scale', 'UG_Scale']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "\n",
    "features = train_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_merged[features]\n",
    "y = train_merged.Is_Shortlisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_sample = np.random.randint(0, X.shape[0], size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[random_sample]\n",
    "y_train = y.iloc[random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_index = X[~X.Internship_ID.isin(X_train.Internship_ID)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X.ix[test_index]\n",
    "y_test = y.ix[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 36) (10989, 36) (15000L,) (10989L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=25)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# clf = LogisticRegression(C=1., penalty='l1', class_weight='auto')\n",
    "# clf = RandomForestClassifier(n_estimators=150, max_depth=6, min_samples_split=3, n_jobs=-1)\n",
    "# clf = GradientBoostingClassifier()\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# pipeline = Pipeline([('scaler', scaler), ('clf', clf)])\n",
    "pipeline = Pipeline([('clf', clf)])\n",
    "# pipeline = Pipeline([('select', select), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'mean score %.2f and std %.2f ' %(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.Skills_required.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.100920\n",
      " 2) Student_ID                     0.100140\n",
      " 3) Expected_Stipend               0.062676\n",
      " 4) Minimum_Duration               0.060714\n",
      " 5) Preferred_location             0.050570\n",
      " 6) Is_Part_Time                   0.049225\n",
      " 7) Skills_required                0.040464\n",
      " 8) Internship_Type                0.040312\n",
      " 9) Internship_Location            0.038752\n",
      "10) Internship_category            0.038656\n",
      "11) No_of_openings                 0.035086\n",
      "12) Stipend_Type                   0.034022\n",
      "13) Stipend1                       0.033303\n",
      "14) Internship_Duration(Months)    0.032804\n",
      "15) Institute_Category             0.028950\n",
      "16) Institute_location             0.022588\n",
      "17) hometown                       0.022531\n",
      "18) Degree                         0.022338\n",
      "19) Stream                         0.021629\n",
      "20) Current_year                   0.019678\n",
      "21) Year_of_graduation             0.018295\n",
      "22) Performance_PG                 0.016937\n",
      "23) Performance_UG                 0.016609\n",
      "24) Performance_12th               0.014980\n",
      "25) Performance_10th               0.013184\n",
      "26) Experience_Type                0.010567\n",
      "27) Location                       0.009923\n",
      "28) num_experience                 0.009442\n",
      "29) num_exp_in_job                 0.006695\n",
      "30) num_awards                     0.005668\n",
      "31) num_previous_internships       0.005609\n",
      "32) is_stipend_performance_or_unpaid 0.005564\n",
      "33) Num_Skills_Required            0.004055\n",
      "34) Stipend_level                  0.003787\n",
      "35) less_than_avg_salary           0.003323\n",
      "36) expectations_match             0.000000\n"
     ]
    }
   ],
   "source": [
    "# RF feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GBM feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsTrain = pipeline.predict_proba(X_train)[:, 1]\n",
    "predsTest = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on training set 0.776711 \n",
      "AUC score on test set 0.581524 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score on training set %f ' %(roc_auc_score(y_train, predsTrain))\n",
    "print 'AUC score on test set %f ' %(roc_auc_score(y_test, predsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                    'Internship_deadline', 'Internship_Profile',\n",
    "                    'Profile', 'Stipend2', 'PG_scale', 'UG_Scale']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "features = test_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test_merged[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/submission.csv')\n",
    "submission['Internship_ID'] = test_merged.Internship_ID\n",
    "submission['Student_ID'] = test_merged.Student_ID\n",
    "submission['Is_Shortlisted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/redate_submission_second.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
