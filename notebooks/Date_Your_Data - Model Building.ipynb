{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', low_memory=False, parse_dates=['Earliest_Start_Date'])\n",
    "students = pd.read_csv('../data/Student.csv')\n",
    "internship = pd.read_csv('../data/Internship.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_hot_encoded_skill_features = internship.columns[13:]\n",
    "internship = internship[internship.columns.drop(one_hot_encoded_skill_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with internship details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_with_internship = pd.merge(train, internship, how='left', on='Internship_ID')\n",
    "test_with_internship = pd.merge(test, internship, how='left', on='Internship_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with student details as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    df['num_experience'] = df.shape[0]\n",
    "    df['num_exp_in_job'] = (df.Experience_Type  == 'job').sum()\n",
    "    df['num_awards'] = (df.Experience_Type  == 'award').sum()\n",
    "    df['num_previous_internships'] = (df.Experience_Type == 'internship').sum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "students_cleaned = students.groupby('Student_ID').apply(feature_engineer)\n",
    "students_cleaned = students_cleaned.groupby('Student_ID').first()\n",
    "students_cleaned = students_cleaned.reset_index()\n",
    "\n",
    "train_merged = pd.merge(train_with_internship, students_cleaned, on='Student_ID', how='left')\n",
    "test_merged = pd.merge(test_with_internship, students_cleaned, on='Student_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save these engineered files so that we don't have to create them every time\n",
    "train_merged.to_csv('../data/train_merged.csv', index=False)\n",
    "test_merged.to_csv('../data/test_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_columns = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date', 'Internship_deadline']\n",
    "\n",
    "train_merged = pd.read_csv('../data/train_merged.csv', parse_dates=date_columns)\n",
    "test_merged = pd.read_csv('../data/test_merged.csv', parse_dates=date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged.Stipend1 = train_merged.Stipend1.fillna(train_merged.Stipend1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert salary from numerical to categorical variable\n",
    "\n",
    "def salary_mapping(salary):\n",
    "    if salary < 2000:\n",
    "        return 'No Expectations'\n",
    "    elif salary >= 2000 and salary < 5000:\n",
    "        return '2-5K'\n",
    "    elif salary >= 5000 and salary < 10000:\n",
    "        return '5-10K'\n",
    "    else:\n",
    "        return '10K+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_merged.loc[:, 'Stipend_level'] = train_merged.Stipend1.map(salary_mapping)\n",
    "test_merged.loc[:, 'Stipend_level'] = test_merged.Stipend1.map(salary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to get average stipend by year of graduation\n",
    "\n",
    "def get_mean_stipend(df):\n",
    "    year_of_grad = df['Year_of_graduation'].unique()\n",
    "    mapping = {}\n",
    "    \n",
    "    for year in year_of_grad:\n",
    "        mapping[year] = df[df['Year_of_graduation'] == year].Stipend1.mean()\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "train_map = get_mean_stipend(train_merged)\n",
    "test_map = get_mean_stipend(test_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate expectation level to see if it matches with current experience of student\n",
    "\n",
    "def calculate_expectation_level_train(row):\n",
    "    year_of_grad = row['Year_of_graduation']\n",
    "    mean_stipend = train_map[year_of_grad]\n",
    "    stipend1 = row['Stipend1']\n",
    "    \n",
    "    return int ( stipend1 < mean_stipend ) \n",
    "\n",
    "def calculate_expectation_level_test(row):\n",
    "    year_of_grad = row['Year_of_graduation']\n",
    "    mean_stipend = test_map[year_of_grad]\n",
    "    stipend1 = row['Stipend1']\n",
    "    \n",
    "    return int ( stipend1 < mean_stipend ) \n",
    "\n",
    "\n",
    "train_merged.loc[:, 'stipend_expectation_by_exp'] = train_merged.apply(calculate_expectation_level_train, axis=1)\n",
    "test_merged.loc[:, 'stipend_expectation_by_exp'] = test_merged.apply(calculate_expectation_level_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# match expectation\n",
    "\n",
    "def check_if_expectations_match(row):\n",
    "    expected_stipend = row['Expected_Stipend']\n",
    "    stipend_level = row['Stipend_level']\n",
    "    \n",
    "    if expected_stipend == 'No Expectations':\n",
    "        return 1\n",
    "    elif expected_stipend == '2-5K':\n",
    "        if stipend_level in ['2-5K', '5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '5-10K':\n",
    "        if stipend_level in ['5-10K', '10K+']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif expected_stipend == '10K+':\n",
    "        if stipend_level == '10K+':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "train_merged.loc[:, 'expectations_match'] = train_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)\n",
    "test_merged.loc[:, 'expectations_match'] = test_merged[['Expected_Stipend', 'Stipend_level']].apply(check_if_expectations_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map percentages to categorical variables\n",
    "\n",
    "def percentage_to_grade(percentage):\n",
    "    if percentage < 40.0:\n",
    "        return 'F'\n",
    "    elif percentage >= 40.0 and percentage < 50.0:\n",
    "        return 'E'\n",
    "    elif percentage >= 50.0 and percentage < 60.0:\n",
    "        return 'D'\n",
    "    elif percentage >= 60.0 and percentage < 70.0:\n",
    "        return 'C'\n",
    "    elif percentage >= 70.0 and percentage < 80.0:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix pg_performace by scale\n",
    "\n",
    "def fix_pg_performance(row):\n",
    "    scale = row['PG_scale']\n",
    "    score = row['Performance_PG']\n",
    "    \n",
    "    if score == 10:\n",
    "        return score * 10.\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "# fix ug_performace by scale\n",
    "\n",
    "def fix_ug_performance(row):\n",
    "    scale = row['UG_Scale']\n",
    "    score = row['Performance_UG']\n",
    "    \n",
    "    if score == 10:\n",
    "        return score * 10.\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "# fix percentages and then convert them to categorical variables\n",
    "train_merged.loc[:, 'Performance_PG'] = train_merged.apply(fix_pg_performance, axis=1)\n",
    "test_merged.loc[:, 'Performance_PG'] = test_merged.apply(fix_pg_performance, axis=1)\n",
    "\n",
    "train_merged.loc[:, 'Performance_UG'] = train_merged.apply(fix_ug_performance, axis=1)\n",
    "test_merged.loc[:, 'Performance_UG'] = test_merged.apply(fix_ug_performance, axis=1)\n",
    "\n",
    "\n",
    "train_merged.loc[:, 'Performance_PG'] = train_merged.Performance_PG.map(percentage_to_grade)\n",
    "test_merged.loc[:, 'Performance_PG'] = test_merged.Performance_PG.map(percentage_to_grade)\n",
    "\n",
    "train_merged.loc[:, 'Performance_UG'] = train_merged.Performance_UG.map(percentage_to_grade)\n",
    "test_merged.loc[:, 'Performance_UG'] = test_merged.Performance_UG.map(percentage_to_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert 12th and 10th class percentages to categorical variables\n",
    "\n",
    "train_merged.loc[:, '12th_performance'] = train_merged.Performance_12th.map(percentage_to_grade)\n",
    "test_merged.loc[:, '12th_performance'] = test_merged.Performance_12th.map(percentage_to_grade)\n",
    "\n",
    "train_merged.loc[:, '10th_performance'] = train_merged.Performance_10th.map(percentage_to_grade)\n",
    "test_merged.loc[:, '10th_performance'] = test_merged.Performance_10th.map(percentage_to_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether earliest start date month was in December or January\n",
    "train_merged.loc[:, 'Earliest_Start_Date_month'] = train_merged.Earliest_Start_Date.dt.month\n",
    "test_merged.loc[:, 'Earliest_Start_Date_month'] = test_merged.Earliest_Start_Date.dt.month\n",
    "\n",
    "train_merged.loc[:, 'is_Dec_or_Jan'] = train_merged.Earliest_Start_Date_month.map(lambda x: int(x == 12 or x == 1))\n",
    "test_merged.loc[:, 'is_Dec_or_Jan'] = test_merged.Earliest_Start_Date_month.map(lambda x: int(x == 12 or x == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# student application count\n",
    "application_count = train_merged.groupby('Student_ID').size()\n",
    "application_count_test = test_merged.groupby('Student_ID').size()\n",
    "\n",
    "train_merged.loc[:, 'whether_applied_previously'] = train_merged.Student_ID.map(lambda x: int( application_count.ix[x] > 1 ))\n",
    "test_merged.loc[:, 'whether_applied_previously'] = test_merged.Student_ID.map(lambda x: int( application_count_test.ix[x] > 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether you have mentioned anything in your profile or not\n",
    "train_merged.loc[:, 'missing_profile'] = train_merged.Profile.isnull().astype(np.int)\n",
    "test_merged.loc[:, 'missing_profile'] = test_merged.Profile.isnull().astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# internship has mentioned skills required\n",
    "train_merged.loc[:, 'missing_skills_required'] = train_merged.Skills_required.isnull().astype(np.int)\n",
    "test_merged.loc[:, 'missing_skills_required'] = test_merged.Skills_required.isnull().astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_features = train_merged.select_dtypes(include=['object']).columns.drop(['Expected_Stipend', 'Preferred_location',\n",
    "                                                                                    'Internship_Profile', 'Skills_required',\n",
    "                                                                                    'Internship_Location', 'hometown',\n",
    "                                                                                    'Institute_location', 'Stream', 'Location'\n",
    "                                                                                   ])\n",
    "\n",
    "for feature in categorical_features:\n",
    "    lbl = LabelEncoder()\n",
    "    feature_range = pd.concat([train_merged[feature], test_merged[feature]], axis=0)\n",
    "    \n",
    "    lbl.fit(feature_range)\n",
    "    train_merged.loc[:, feature] = lbl.transform(train_merged[feature])\n",
    "    test_merged.loc[:, feature] = lbl.transform(test_merged[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing value with 999\n",
    "\n",
    "train_merged = train_merged.fillna(999)\n",
    "test_merged = test_merged.fillna(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                    'Is_Shortlisted', 'Internship_deadline', 'Preferred_location', 'Internship_Profile', \n",
    "                    'Skills_required', 'Internship_category', 'Profile',\n",
    "                    'Stipend2', 'PG_scale', 'UG_Scale', 'Internship_Location', 'Expected_Stipend',\n",
    "                    'Degree', 'Stream', 'hometown', 'Institute_location', 'Location',\n",
    "                    'Performance_12th', 'Performance_10th']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "features = train_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_merged[features]\n",
    "y = train_merged.Is_Shortlisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a random sample of a given size\n",
    "random_sample = np.random.randint(0, X.shape[0], size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[random_sample]\n",
    "y_train = y.iloc[random_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# consider those internships which are not in the training set\n",
    "test_index = X[~X.Internship_ID.isin(X_train.Internship_ID)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X.ix[test_index]\n",
    "y_test = y.ix[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 29) (10520, 29) (15000,) (10520,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=50)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# clf = LogisticRegression(C=1., penalty='l1', class_weight='auto')\n",
    "# clf = RandomForestClassifier(n_estimators=1000, max_depth=4, min_samples_split=10, min_samples_leaf=10, n_jobs=-1)\n",
    "clf = ExtraTreesClassifier(n_estimators=3000, min_samples_split=10, min_samples_leaf=10, max_depth=5, n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([('clf', clf)])\n",
    "# pipeline = Pipeline([('select', select), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=10, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=3000, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.116771\n",
      " 2) Student_ID                     0.109342\n",
      " 3) Minimum_Duration               0.080221\n",
      " 4) Is_Part_Time                   0.069647\n",
      " 5) Internship_Type                0.047877\n",
      " 6) No_of_openings                 0.039503\n",
      " 7) Stipend_Type                   0.038522\n",
      " 8) Stipend1                       0.035383\n",
      " 9) Internship_Duration(Months)    0.029671\n",
      "10) PR                             0.028314\n",
      "11) UI                             0.027536\n",
      "12) Marketing                      0.026056\n",
      "13) Media                          0.023554\n",
      "14) Social                         0.019316\n",
      "15) Design                         0.018387\n",
      "16) Web                            0.016246\n",
      "17) Development                    0.014927\n",
      "18) Business                       0.014422\n",
      "19) Research                       0.014019\n",
      "20) Writing                        0.013950\n",
      "21) Plan                           0.013721\n",
      "22) Creative                       0.012162\n",
      "23) Process                        0.012035\n",
      "24) Database                       0.010888\n",
      "25) Strategy                       0.010007\n",
      "26) Designing                      0.009801\n",
      "27) Analysis                       0.009631\n",
      "28) Facebook                       0.008165\n",
      "29) Communication                  0.007802\n",
      "30) Rest                           0.007383\n",
      "31) Android                        0.007135\n",
      "32) Presentation                   0.006833\n",
      "33) Media Marketing                0.006653\n",
      "34) Twitter                        0.006409\n",
      "35) Social Media Marketing         0.005975\n",
      "36) Operations                     0.005477\n",
      "37) Java                           0.004683\n",
      "38) Quality                        0.004479\n",
      "39) HTML                           0.004138\n",
      "40) Blogs                          0.004057\n",
      "41) Digital Marketing              0.003564\n",
      "42) PHP                            0.003555\n",
      "43) Market Research                0.003104\n",
      "44) Recruitment                    0.003060\n",
      "45) Testing                        0.002901\n",
      "46) CSS                            0.002849\n",
      "47) Planning                       0.002639\n",
      "48) API                            0.002553\n",
      "49) Editing                        0.002427\n",
      "50) Content Writing                0.002285\n",
      "51) Innovative                     0.002063\n",
      "52) Lead Generation                0.001941\n",
      "53) Mobile App                     0.001909\n",
      "54) SQL                            0.001895\n",
      "55) Accounts                       0.001688\n",
      "56) Reporting                      0.001649\n",
      "57) JavaScript                     0.001521\n",
      "58) Documentation                  0.001331\n",
      "59) iOS                            0.001324\n",
      "60) Branding                       0.001273\n",
      "61) ACTING                         0.001263\n",
      "62) Analytics                      0.001245\n",
      "63) Initiative                     0.001228\n",
      "64) Advertising                    0.001199\n",
      "65) Cold Calling                   0.001008\n",
      "66) Sourcing                       0.000935\n",
      "67) ERP                            0.000735\n",
      "68) NGO                            0.000694\n",
      "69) Environment                    0.000655\n",
      "70) Networking                     0.000612\n",
      "71) Production                     0.000545\n",
      "72) MySQL                          0.000508\n",
      "73) ISO                            0.000425\n",
      "74) Marketing Strategy             0.000365\n",
      "75) Survey                         0.000364\n",
      "76) Visio                          0.000231\n",
      "77) App Development                0.000186\n",
      "78) Front End                      0.000176\n",
      "79) web development                0.000161\n",
      "80) Integration                    0.000158\n",
      "81) HTML5                          0.000157\n",
      "82) jQuery                         0.000125\n",
      "83) Server                         0.000124\n",
      "84) Coding                         0.000099\n",
      "85) MBA                            0.000093\n",
      "86) Content Creation               0.000070\n",
      "87) Reading                        0.000010\n",
      "88) B2B                            0.000000\n",
      "89) Content Development            0.000000\n",
      "90) Storm                          0.000000\n",
      "91) E-commerce                     0.000000\n",
      "92) Databases                      0.000000\n",
      "93) Programming                    0.000000\n",
      "94) Wordpress                      0.000000\n",
      "95) Outreach                       0.000000\n",
      "96) NABL                           0.000000\n",
      "97) Web Design                     0.000000\n",
      "98) Architecture                   0.000000\n",
      "99) Web Application                0.000000\n",
      "100) Adobe                          0.000000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-6b5e7522ea53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%2d) %-*s %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "# RF feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Internship_ID                  0.112838\n",
      " 2) Student_ID                     0.110488\n",
      " 3) Expected_Stipend               0.081714\n",
      " 4) Minimum_Duration               0.073927\n",
      " 5) Preferred_location             0.049659\n",
      " 6) Is_Part_Time                   0.047065\n",
      " 7) Internship_Type                0.040350\n",
      " 8) Internship_Location            0.039712\n",
      " 9) Internship_category            0.039164\n",
      "10) No_of_openings                 0.038776\n",
      "11) Stipend_Type                   0.037496\n",
      "12) Stipend1                       0.029431\n",
      "13) Internship_Duration(Months)    0.027383\n",
      "14) Institute_Category             0.023922\n",
      "15) Institute_location             0.021115\n",
      "16) hometown                       0.020669\n",
      "17) Stream                         0.019968\n",
      "18) Current_year                   0.019587\n",
      "19) Year_of_graduation             0.019051\n",
      "20) Performance_PG                 0.018515\n",
      "21) Performance_UG                 0.017904\n",
      "22) Performance_12th               0.015356\n",
      "23) Performance_10th               0.013894\n",
      "24) Experience_Type                0.013624\n",
      "25) Location                       0.013146\n",
      "26) num_experience                 0.012727\n",
      "27) num_exp_in_job                 0.008740\n",
      "28) num_awards                     0.007190\n",
      "29) num_previous_internships       0.006369\n",
      "30) is_stipend_performance_or_unpaid 0.005064\n",
      "31) Num_Skills_Required            0.004476\n",
      "32) Stipend_level                  0.004263\n",
      "33) less_than_avg_salary           0.004085\n",
      "34) expectations_match             0.002333\n",
      "35) Earliest_Start_Date_month      0.000000\n",
      "36) is_Dec_or_Jan                  0.000000\n"
     ]
    }
   ],
   "source": [
    "# GBM feature importance\n",
    "forest = pipeline.get_params()['clf']\n",
    "importances = forest.feature_importances_ \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X_train.columns[f], importances[indices[f]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsTrain = (pipeline.predict_proba(X_train)[:, 1])\n",
    "predsTest = (pipeline.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on training set 0.686237 \n",
      "AUC score on test set 0.603352 \n"
     ]
    }
   ],
   "source": [
    "print 'AUC score on training set %f ' %(roc_auc_score(y_train, predsTrain))\n",
    "print 'AUC score on test set %f ' %(roc_auc_score(y_test, predsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf', ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=10, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=3000, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['Earliest_Start_Date', 'Start_Date', 'Start Date', 'End Date',\n",
    "                    'Internship_deadline', 'Preferred_location', 'Internship_Profile', \n",
    "                    'Skills_required', 'Internship_category', 'Profile',\n",
    "                    'Stipend2', 'PG_scale', 'UG_Scale', 'Internship_Location', 'Expected_Stipend',\n",
    "                    'Degree', 'Stream', 'hometown', 'Institute_location', 'Location',\n",
    "                    'Performance_12th', 'Performance_10th']\n",
    "\n",
    "features_to_drop.extend(list(train_merged.columns[20:293]))\n",
    "features = test_merged.columns.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = test_merged[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = (pipeline.predict_proba(test_features)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/submission.csv')\n",
    "submission['Internship_ID'] = test_merged.Internship_ID\n",
    "submission['Student_ID'] = test_merged.Student_ID\n",
    "submission['Is_Shortlisted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/redate_submission_extra_trees_classifier_3000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
